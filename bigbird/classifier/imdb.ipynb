{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BigBirdGPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YONnGjpAYUdU"
      },
      "source": [
        "\n",
        "<a href=\"https://colab.research.google.com/github/google-research/bigbird/blob/master/bigbird/classifier/imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrtR2urJV3ST"
      },
      "source": [
        "##### Copyright 2020 The BigBird Authors\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyasTfa-LVLe"
      },
      "source": [
        "# Copyright 2020 The BigBird Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcZZRDx505hq"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N94UyOdA0mCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de96a27-ee2d-4e03-b82e-7c029fd4c829"
      },
      "source": [
        "!pip install git+https://github.com/google-research/bigbird.git -q\n",
        "!pip install wandb -qqq\n",
        "import wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.2 MB 10.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 57.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 58.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 23.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 679 kB 74.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 76.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 21.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 649 kB 66.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 981 kB 56.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 366 kB 79.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 191 kB 79.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 365 kB 72.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 251 kB 73.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 191 kB 73.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 81.7 MB/s \n",
            "\u001b[?25h  Building wheel for bigbird (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 76.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 73.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "hMCwGJSFSsuY",
        "outputId": "da30673a-f39d-4129-c517-c828dd9d9f46"
      },
      "source": [
        "wandb.init(project=\"uncategorized\", entity='notyeshwanthreddy')\n",
        "config = wandb.config"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.0<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">dauntless-voice-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/notyeshwanthreddy/uncategorized\" target=\"_blank\">https://wandb.ai/notyeshwanthreddy/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/notyeshwanthreddy/uncategorized/runs/2qrfkzx6\" target=\"_blank\">https://wandb.ai/notyeshwanthreddy/uncategorized/runs/2qrfkzx6</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210811_173212-2qrfkzx6</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0irPwcbBYvDV"
      },
      "source": [
        "from bigbird.core import flags\n",
        "from bigbird.core import modeling\n",
        "from bigbird.core import utils\n",
        "from bigbird.classifier import run_classifier\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "if not hasattr(FLAGS, \"f\"): flags.DEFINE_string(\"f\", \"\", \"\")\n",
        "FLAGS(sys.argv)\n",
        "\n",
        "tf.enable_v2_behavior()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJexg2zsxfHo"
      },
      "source": [
        "## Set options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rph2sJ75kBNA"
      },
      "source": [
        "FLAGS.data_dir = \"tfds://imdb_reviews/plain_text\"\n",
        "FLAGS.attention_type = \"block_sparse\"\n",
        "# FLAGS.max_encoder_length = 4096  # reduce for quicker demo on free colab\n",
        "FLAGS.max_encoder_length = 1024  # reduce for quicker demo on free colab\n",
        "FLAGS.learning_rate = 1e-5\n",
        "FLAGS.num_train_steps = 2000\n",
        "FLAGS.attention_probs_dropout_prob = 0.0\n",
        "FLAGS.hidden_dropout_prob = 0.0\n",
        "FLAGS.use_gradient_checkpointing = True\n",
        "FLAGS.vocab_model_file = \"gpt2\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuxI3V_3j57Y"
      },
      "source": [
        "bert_config = flags.as_dictionary()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRF4TUEQxjXJ"
      },
      "source": [
        "## Define classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3yNdo5toQwq"
      },
      "source": [
        "model = modeling.BertModel(bert_config)\n",
        "headl = run_classifier.ClassifierLossLayer(\n",
        "        bert_config[\"hidden_size\"], bert_config[\"num_labels\"],\n",
        "        bert_config[\"hidden_dropout_prob\"],\n",
        "        utils.create_initializer(bert_config[\"initializer_range\"]),\n",
        "        name=bert_config[\"scope\"]+\"/classifier\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXOY78vbqHX9"
      },
      "source": [
        "@tf.function(experimental_compile=True)\n",
        "def fwd_bwd(features, labels):\n",
        "  with tf.GradientTape() as g:\n",
        "    _, pooled_output = model(features, training=True)\n",
        "    loss, log_probs = headl(pooled_output, labels, True)\n",
        "  grads = g.gradient(loss, model.trainable_weights+headl.trainable_weights)\n",
        "  return loss, log_probs, grads"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzoTMyQlxsRo"
      },
      "source": [
        "## Dataset pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo-NQTDZZs51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40c7dcc-856d-4056-baf9-1c5a9070d080"
      },
      "source": [
        "train_input_fn = run_classifier.input_fn_builder(\n",
        "        data_dir=FLAGS.data_dir,\n",
        "        vocab_model_file=FLAGS.vocab_model_file,\n",
        "        max_encoder_length=FLAGS.max_encoder_length,\n",
        "        substitute_newline=FLAGS.substitute_newline,\n",
        "        is_training=True)\n",
        "dataset = train_input_fn({'batch_size': 8})"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bigbird/classifier/run_classifier.py:165: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  deterministic=is_training)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRvmfaNUi-V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0d5184-8dbf-44d7-dbc7-3743221b5fac"
      },
      "source": [
        "# inspect at a few examples\n",
        "for ex in dataset.take(3):\n",
        "  print(ex)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(8, 1024), dtype=int32, numpy=\n",
            "array([[   65,   733,   474, ...,     0,     0,     0],\n",
            "       [   65,   415, 26500, ...,     0,     0,     0],\n",
            "       [   65,   484, 20677, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [   65,   418,  1150, ...,     0,     0,     0],\n",
            "       [   65,  9271,  5714, ...,     0,     0,     0],\n",
            "       [   65,  8301,   113, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 1, 1, 1, 1, 0, 1, 0], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(8, 1024), dtype=int32, numpy=\n",
            "array([[  65, 1182,  358, ...,    0,    0,    0],\n",
            "       [  65,  871,  419, ...,    0,    0,    0],\n",
            "       [  65,  415, 1908, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  65,  484, 1722, ...,    0,    0,    0],\n",
            "       [  65,  876, 1154, ...,    0,    0,    0],\n",
            "       [  65,  415, 1092, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 1, 0, 0, 1, 0, 0, 1], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(8, 1024), dtype=int32, numpy=\n",
            "array([[   65,   456,   382, ...,     0,     0,     0],\n",
            "       [   65,   484, 34679, ...,     0,     0,     0],\n",
            "       [   65, 16224,   112, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [   65,   484,  3822, ...,     0,     0,     0],\n",
            "       [   65,   484,  2747, ...,     0,     0,     0],\n",
            "       [   65,   415,  1208, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 0, 1, 0], dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYCyGH56zOOU"
      },
      "source": [
        "## (Optionally) Check outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uQOwyGQzRKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e38628c-294d-474b-afec-11d16dea253c"
      },
      "source": [
        "loss, log_probs, grads = fwd_bwd(ex[0], ex[1])\n",
        "print('Loss: ', loss.numpy())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.62117565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz_LdCCdyDCR"
      },
      "source": [
        "## (Optionally) Load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRa2dD1RzLN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d331653b-8a43-459e-ec38-40cc10af0b91"
      },
      "source": [
        "ckpt_path = 'gs://bigbird-transformer/pretrain/bigbr_base/model.ckpt-0'\n",
        "ckpt_reader = tf.compat.v1.train.NewCheckpointReader(ckpt_path)\n",
        "model.set_weights([ckpt_reader.get_tensor(v.name[:-2]) for v in tqdm(model.trainable_weights, position=0)])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 199/199 [00:45<00:00,  4.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6-BziYxzL3U"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWjkDvu9k7ie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176b1b58-561a-4b8d-f793-c1ad8e44ac0b"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(FLAGS.learning_rate)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "for i, ex in enumerate(tqdm(dataset.take(FLAGS.num_train_steps), position=0)):\n",
        "  loss, log_probs, grads = fwd_bwd(ex[0], ex[1])\n",
        "  opt.apply_gradients(zip(grads, model.trainable_weights+headl.trainable_weights))\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tf.one_hot(ex[1], 2), log_probs)\n",
        "  if i% 200 == 0:\n",
        "    print('Loss = {}  Accuracy = {}'.format(train_loss.result().numpy(), train_accuracy.result().numpy()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2000 [00:07<4:25:22,  7.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.7722638845443726  Accuracy = 0.375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 201/2000 [07:28<1:05:42,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.4163071811199188  Accuracy = 0.8252487778663635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 401/2000 [14:48<58:16,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.34832972288131714  Accuracy = 0.8615959882736206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 601/2000 [22:08<51:12,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.31350818276405334  Accuracy = 0.877703845500946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 801/2000 [29:27<44:03,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.2841528058052063  Accuracy = 0.892166018486023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1001/2000 [36:47<36:28,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.26684820652008057  Accuracy = 0.897602379322052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1201/2000 [44:07<29:23,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.25541743636131287  Accuracy = 0.9019566774368286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 1401/2000 [51:26<22:01,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.24668189883232117  Accuracy = 0.9052462577819824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 1601/2000 [58:45<14:39,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.23745958507061005  Accuracy = 0.9099000692367554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 1801/2000 [1:06:05<07:17,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.23041319847106934  Accuracy = 0.9128261804580688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [1:13:22<00:00,  2.20s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXjkdtyKMAbP"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc3OatxlMCk3"
      },
      "source": [
        "@tf.function(experimental_compile=True)\n",
        "def fwd_only(features, labels):\n",
        "  _, pooled_output = model(features, training=False)\n",
        "  loss, log_probs = headl(pooled_output, labels, False)\n",
        "  return loss, log_probs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mq_xhMzef42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a0d79e-5076-4fe9-f188-28078d3c028d"
      },
      "source": [
        "eval_input_fn = run_classifier.input_fn_builder(\n",
        "        data_dir=FLAGS.data_dir,\n",
        "        vocab_model_file=FLAGS.vocab_model_file,\n",
        "        max_encoder_length=FLAGS.max_encoder_length,\n",
        "        substitute_newline=FLAGS.substitute_newline,\n",
        "        is_training=False)\n",
        "eval_dataset = eval_input_fn({'batch_size': 8})"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bigbird/classifier/run_classifier.py:165: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  deterministic=is_training)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqPN4R8kerUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a84555-ffea-4b76-c1bd-2473ab62efd2"
      },
      "source": [
        "eval_loss = tf.keras.metrics.Mean(name='eval_loss')\n",
        "eval_accuracy = tf.keras.metrics.CategoricalAccuracy(name='eval_accuracy')\n",
        "\n",
        "for ex in tqdm(eval_dataset, position=0):\n",
        "  loss, log_probs = fwd_only(ex[0], ex[1])\n",
        "  eval_loss(loss)\n",
        "  eval_accuracy(tf.one_hot(ex[1], 2), log_probs)\n",
        "print('Loss = {}  Accuracy = {}'.format(eval_loss.result().numpy(), eval_accuracy.result().numpy()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3125/3125 [30:52<00:00,  1.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.15144120156764984  Accuracy = 0.9464799761772156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EesyASsBp30m",
        "outputId": "3eb996e1-0cf1-4074-dcb8-93259a29fd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in (eval_dataset.take(1)):\n",
        "  print(i)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(8, 1024), dtype=int32, numpy=\n",
            "array([[   65,  1419,   490, ...,     0,     0,     0],\n",
            "       [   65,   418,  2143, ...,     0,     0,     0],\n",
            "       [   65, 23777, 41003, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [   65,  1547,   661, ...,     0,     0,     0],\n",
            "       [   65,   871,  2747, ...,     0,     0,     0],\n",
            "       [   65,   484,  3451, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(8,), dtype=int32, numpy=array([1, 1, 0, 1, 1, 0, 1, 1], dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ_Ju2LkySRm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}